{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# nlp\n",
    "import gensim\n",
    "import string\n",
    "import re    #for regex\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "\n",
    "#feature enginnering & clustering\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('StackOverflow.txt') as f:\n",
    "    sents = f.readlines()\n",
    "text = [x.strip() for x in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':[]})\n",
    "df.text= data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I fill a DataSet or a DataTable from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do you page a collection with LINQ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Subversion clients for Windows Vista (64bit)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Practice: Collaborative Environment, Bin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Visual Studio Setup Project - Per User Registr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  How do I fill a DataSet or a DataTable from a ...\n",
       "1            How do you page a collection with LINQ?\n",
       "2  Best Subversion clients for Windows Vista (64bit)\n",
       "3  Best Practice: Collaborative Environment, Bin ...\n",
       "4  Visual Studio Setup Project - Per User Registr..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I fill a DataSet or a DataTable from a LINQ query resultset ?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I fill a DataSet or a DataTable from a LINQ query resultset ?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "'''\n",
    "1. lower case\n",
    "2. tyokenize:bag-of-words, n-grams\n",
    "2. stemming,lemmatization\n",
    "3. remove stopwords and punctuations\n",
    "4. generate features: model in VSM: e.g.,tf-idf,co-occurence vector; wor2vec,sent2vec, doc2vec.\n",
    "5. clustering\n",
    "6. auto-tagging (topic extraction) based on clustering centroids\n",
    "7. Evaluation\n",
    "'''\n",
    "# 1.remove punctuations\n",
    "df['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-Z]+', ' ', x))\n",
    "# 2.lowercase\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "# 3.lemmatize\n",
    "wnl = WordNetLemmatizer()\n",
    "df['text'] = df['text'].apply(lambda x: wnl.lemmatize(x))\n",
    "# 4.tokenize\n",
    "tokenizer = TweetTokenizer()\n",
    "df['text'] = df['text'].apply(lambda x: tokenizer.tokenize(x))\n",
    "# 5. remove stop words\n",
    "df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "X_text = tfidf.fit_transform(data['text'])\n",
    "\n",
    "# reduce dimensions\n",
    "\n",
    "svd = TruncatedSVD(n_components=20, random_state = 0)\n",
    "X_2d = svd.fit_transform(X_text)\n",
    "\n",
    "# fit k-mean clustering\n",
    "kmeans = KMeans(n_clusters=20, random_state = 0)\n",
    "\n",
    "# predict our clusters for each song\n",
    "X_clustered = kmeans.fit_predict(X_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11672334, -0.10728258,  0.24545832, ..., -0.04339518,\n",
       "         0.01154854,  0.00940378],\n",
       "       [ 0.19697021, -0.15010464,  0.22516146, ..., -0.0751901 ,\n",
       "        -0.04147058,  0.07976761],\n",
       "       [ 0.04918095,  0.01190245, -0.01406529, ..., -0.03167848,\n",
       "        -0.0547745 , -0.01532782],\n",
       "       ...,\n",
       "       [ 0.11837154, -0.02279527, -0.13462921, ...,  0.01994234,\n",
       "        -0.01191106, -0.01859824],\n",
       "       [ 0.160087  , -0.06246806, -0.14404917, ...,  0.19670384,\n",
       "         0.01752477, -0.02796627],\n",
       "       [ 0.10745115, -0.04671286, -0.07798497, ..., -0.00615473,\n",
       "        -0.0086188 , -0.02439176]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cluster         0         1         2         3         4         5  \\\n",
      "0        5  0.116723 -0.107283  0.245458  0.126023 -0.041596 -0.006512   \n",
      "1        5  0.196970 -0.150105  0.225161  0.262281 -0.041789 -0.020312   \n",
      "2        6  0.049181  0.011902 -0.014065 -0.022295 -0.013936 -0.000844   \n",
      "3       15  0.069343  0.012630 -0.032027 -0.038808 -0.030718 -0.008885   \n",
      "4        3  0.159891  0.351006  0.058518  0.036197  0.037413 -0.002895   \n",
      "\n",
      "          6         7         8    ...           10        11        12  \\\n",
      "0 -0.024742 -0.021847 -0.005373    ...     0.018872  0.018562 -0.000747   \n",
      "1 -0.015387 -0.036667 -0.010797    ...     0.036786  0.036473 -0.028929   \n",
      "2 -0.022409  0.020671 -0.016214    ...    -0.018265  0.054042  0.031884   \n",
      "3 -0.071513  0.018801 -0.026893    ...    -0.036176  0.138263  0.144324   \n",
      "4  0.010041 -0.008355 -0.001647    ...     0.023871 -0.016851 -0.000872   \n",
      "\n",
      "         13        14        15        16        17        18        19  \n",
      "0 -0.008361  0.017209 -0.051132  0.009959 -0.043395  0.011549  0.009404  \n",
      "1 -0.016853  0.040532 -0.130165  0.014229 -0.075190 -0.041471  0.079768  \n",
      "2  0.024017  0.019192  0.024676  0.005178 -0.031678 -0.054774 -0.015328  \n",
      "3  0.090723 -0.006228 -0.037573 -0.054391 -0.020725 -0.085787 -0.045356  \n",
      "4 -0.005669  0.004776  0.006088 -0.007170 -0.002882 -0.001666 -0.002370  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "         Cluster\n",
      "Cluster         \n",
      "0            830\n",
      "1            811\n",
      "2            438\n",
      "3            695\n",
      "4            733\n",
      "5            837\n",
      "6           5436\n",
      "7            805\n",
      "8            721\n",
      "9            781\n",
      "10           855\n",
      "11           731\n",
      "12           827\n",
      "13           863\n",
      "14           812\n",
      "15           609\n",
      "16           634\n",
      "17          1161\n",
      "18           774\n",
      "19           647\n"
     ]
    }
   ],
   "source": [
    "# display by groups\n",
    "df_plot = pd.DataFrame(list(X_2d), list(X_clustered))\n",
    "df_plot = df_plot.reset_index()\n",
    "df_plot.rename(columns = {'index': 'Cluster'}, inplace = True)\n",
    "df_plot['Cluster'] = df_plot['Cluster'].astype(int)\n",
    "\n",
    "print(df_plot.head())\n",
    "\n",
    "print(df_plot.groupby('Cluster').agg({'Cluster': 'count'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "represent sents in vector space by word2vec model.\n",
    "Try with different distace meatures.\n",
    "'''\n",
    "# 1. load word-embedding\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/work/courses/unix/T/ELEC/E5550/data/embeddings/GoogleNews-vectors-negative300.bin.gz',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38febdecf8074d579b2c6e7073bc2ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. sent2vec/doc2vec\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def sent2vector(sent):\n",
    "   # words = word_tokenize(sent.lower())\n",
    "    words = sent\n",
    "    # Here we weight-average each word in sentence by 1/log(count[word])\n",
    "    emb = [model[w] for w in words if w in model]\n",
    "    weights = [1./cnt[w] for w in words if w in model]\n",
    "    \n",
    "    if len(emb) == 0:\n",
    "        return np.zeros(100, dtype=np.float32)\n",
    "    else:\n",
    "        return np.dot(weights, emb) / np.sum(weights)\n",
    "from collections import Counter\n",
    "\n",
    "cnt = Counter({k:v.count for k, v in model.vocab.items()})\n",
    "X = np.array(list(map(sent2vector, tqdm_notebook(df['text']))))\n",
    "df['sent_vectors'] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO:\n",
    "Evaluate the result using different methods:NMI,accuracy\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
